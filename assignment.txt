Assignment: AI Ethics
Theme:Â "Designing Responsible and Fair AI Systems"Â ğŸŒâš–ï¸

Objective & Guidelnes

This assignment evaluates your understanding ofÂ AI ethics principles, ability to identify and mitigate biases, and skill in applying ethical frameworks to real-world scenarios. You will analyze case studies, audit AI systems, and propose solutions to ethical dilemmas.

The Asignment should be handled in peer groups.Â 

Submission Guidelines

Written Answers: PDF with case study analyses and reflections. (Group Peer Reviews)

Code & Visualizations: Jupyter Notebook or Python script with fairness audit. (Shared on GitHub)

Bonus Task: Separate document (To be shared as an article in the PLP Academy Community).

Grading Rubric
Criteria	Weight
Theoretical Accuracy	30%
Case Study Depth & Solutions	40%
Technical Audit Execution	25%
Reflection & Creativity	5%

Tools & Resources

Libraries:Â AI Fairness 360,Â Pandas,Â Matplotlib.

Datasets: COMPAS (provided),Â ProPublicaâ€™s Analysis.

Frameworks:Â EU Ethics Guidelines for Trustworthy AI.

Why This Matters

Why This Matters

Societal Impact: Ethical AI prevents harm and fosters trust in technology.

Career Skill: Employers prioritize ethical competency in AI roles.

Deadline: 7 days. Build AI thatâ€™s fair, transparent, and human-centric! ğŸŒŸ

Need Help?

UseÂ AI Fairness 360Â GitHub Repository.

Join the PLP Academy Community discussion: #AIEthicsAssignment.

Pro Tip: Start with fairness metrics likeÂ disparate impact ratioÂ andÂ equal opportunity difference. Small steps lead to big ethical wins! ğŸ”

Part 1: Theoretical UnderstandingÂ (30%)
1. Short Answer Questions

Q1: DefineÂ algorithmic biasÂ and provide two examples of how it manifests in AI systems.

Q2: Explain the difference betweenÂ transparencyÂ andÂ explainabilityÂ in AI. Why are both important?

Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?

2. Ethical Principles Matching

Match the following principles to their definitions:

A) Justice

B) Non-maleficence

C) Autonomy

D) Sustainability

Ensuring AI does not harm individuals or society.

Respecting usersâ€™ right to control their data and decisions.

Designing AI to be environmentally friendly.

Fair distribution of AI benefits and risks.



Part 2: Case Study AnalysisÂ (40%)
Case 1: Biased Hiring Tool

Scenario: Amazonâ€™s AI recruiting tool penalized female candidates.

Tasks:

Identify the source of bias (e.g., training data, model design).

Propose three fixes to make the tool fairer.

Suggest metrics to evaluate fairness post-correction.

Case 2: Facial Recognition in Policing

Scenario: A facial recognition system misidentifies minorities at higher rates.

Tasks:

Discuss ethical risks (e.g., wrongful arrests, privacy violations).

Recommend policies for responsible deployment.

Part 3: Practical AuditÂ (25%)
Task: Audit a Dataset for Bias

Dataset:Â COMPAS Recidivism Dataset.

Goal:

Use Python andÂ AI Fairness 360Â (IBMâ€™s toolkit) to analyze racial bias in risk scores.

Generate visualizations (e.g., disparity in false positive rates).

Write a 300-word report summarizing findings and remediation steps.

Deliverable: Code + report.

Part 4: Ethical ReflectionÂ (5%)

Prompt: Reflect on a personal project (past or future). How will you ensure it adheres to ethical AI principles?

Bonus TaskÂ (Extra 10%)

Policy Proposal: Draft a 1-page guideline forÂ ethical AI use in healthcare. Include:

Patient consent protocols.

Bias mitigation strategies.

Transparency requirements.